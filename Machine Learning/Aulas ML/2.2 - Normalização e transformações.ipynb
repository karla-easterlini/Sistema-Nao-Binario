{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformação e normalização\n",
    "============================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos iniciar criando um `DataFrame`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Nome  Idade  Bigode épico? Altura\n",
      "0     Platão   80.0           True   <NA>\n",
      "1   Sócrates   71.0           True   <NA>\n",
      "2  Descartes   53.0          False   1.55\n",
      "3  Nietzsche   55.0           True    1.7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dicionario_contendo_os_dados = {\n",
    "    \"Nome\": [\"Platão\", \"Sócrates\", \"Descartes\", \"Nietzsche\"],\n",
    "    \"Idade\": [80, 71, 53, 55.0],\n",
    "    \"Bigode épico?\": [True, True, False, True],\n",
    "    \"Altura\": [pd.NA, pd.NA, 1.55, 1.70],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(dicionario_contendo_os_dados)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformações\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte do tratamento de dados envolve aplicarmos funções nos dados. Chamamos isso de transformação. Quem sabe você tenha uma temperatura em graus Celsius e queira ela em Kelvin. Neste caso, você terá que aplicar uma função que altere todos os valores da coluna original adicionando 273,15 a eles.\n",
    "\n",
    "Vamos converter a idade dos nossos filósofos de anos para segundos! Note que estamos fazendo cópias do `DataFrame` original para cada alteração. Isso não é obrigatório nem necessário. Fizemos isso aqui para não ter problema na ordem de execução das células deste notebook. Inclusive, se seu conjunto de dados for muito grande, pode não ser uma boa prática ficar criando cópias!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Nome         Idade  Bigode épico? Altura\n",
      "0     Platão  2.460672e+09           True   <NA>\n",
      "1   Sócrates  2.183846e+09           True   <NA>\n",
      "2  Descartes  1.630195e+09          False   1.55\n",
      "3  Nietzsche  1.691712e+09           True    1.7\n"
     ]
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2[\"Idade\"] = df2[\"Idade\"] * 356 * 24 * 3600\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos um problema, a coluna `Idade` contém valores muito grandes! Quem sabe seja razoável aplicar um logaritmo aqui!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Nome     Idade  Bigode épico? Altura\n",
      "0     Platão  9.391054           True   <NA>\n",
      "1   Sócrates  9.339222           True   <NA>\n",
      "2  Descartes  9.212240          False   1.55\n",
      "3  Nietzsche  9.228326           True    1.7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df2[\"Idade\"] = np.log10(df2[\"Idade\"])\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz parte do pré-processamento de dados refletir sobre quais transformações são interessantes/necessárias nos seus dados. Em particular, <u>se você tem alguma grandeza numérica que varia mais que uma ordem de grandeza</u>, considere a possibilidade de trabalhar com o logaritmo dessa grandeza para evitar que os números muito grandes dominem os cálculos em relação aos números muito pequenos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um tipo de transformação de dados muito comum é a chamada *normalização*. Muitos algoritmos de aprendizado de máquina <u>requerem</u> que os dados estejam normalizados. Redes neurais artificiais, por exemplo, se beneficiam quando os dados de entrada estão entre $-1$ e $1$. Certos modelos assumem que os dados vêm de uma distribuição com média zero e desvio padrão um e irão se comportar de maneira subótima quando esse não é o caso.\n",
    "\n",
    "Existem três tipos usuais de normalizações lineares para dados numéricos tabulados: normalização padrão (z-score), normalização pelo máximo absoluto e normalização pelo mínimo e máximo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização padrão\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <u>normalização padrão</u> altera a média dos dados para zero e o desvio padrão dos dados para um. Ela pode ser calculada com a equação abaixo, onde $\\mu$ é a média dos dados $x$, $\\sigma$ é o desvio padrão dos dados $x$, $x_i$ é o exemplo $i$ do conjunto de dados $x$ e $z_i$ é o valor normalizado do exemplo $i$ do conjunto de dados $x$.\n",
    "\n",
    "$$z_i = \\frac{x_i - \\mu}{\\sigma}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Nome  Idade  Bigode épico? Altura  Idade_zscore\n",
      "0     Platão   80.0           True   <NA>      1.175689\n",
      "1   Sócrates   71.0           True   <NA>      0.481840\n",
      "2  Descartes   53.0          False   1.55     -0.905858\n",
      "3  Nietzsche   55.0           True    1.7     -0.751670\n"
     ]
    }
   ],
   "source": [
    "media = df['Idade'].mean()\n",
    "desvio_padrao = df['Idade'].std()\n",
    "\n",
    "df['Idade_zscore'] = (df['Idade'] - media) / desvio_padrao\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta normalização, nosso interesse *não* é inferir a média e o desvio padrão da população. Desta forma, computamos $\\mu$ e $\\sigma$ usando as formulas para populações e não para amostras (os próprios símbolos já sugerem isso também).\n",
    "\n",
    "Note que esta transformação não altera o quão normalmente distribuídos estão seus dados, apenas translada e &ldquo;estica/comprime&rdquo; seus dados para que apresentem média 0 e desvio padrão 1.\n",
    "\n",
    "Certos algoritmos esperam que os dados tenham distribuições comparáveis. Um exemplo são algoritmos baseados em distâncias como o $k$​-vizinhos mais próximos. Neste caso, usar o normalizador padrão é uma boa estratégia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização pelo máximo absoluto\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <u>normalização pelo máximo absoluto</u> faz com que todos os dados fiquem entre o intervalo $[-1, 1]$. Para calcular esta normalização basta dividir os dados pelo valor máximo absoluto. Veja a equação abaixo que computa o valor transformado $n_i$ do exemplo $i$.\n",
    "\n",
    "$$ n_i = \\frac{x_i}{\\max(|x|)} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Nome  Idade  Bigode épico? Altura  Idade_zscore  Idade_norm_max_abs\n",
      "0     Platão   80.0           True   <NA>      1.175689              1.0000\n",
      "1   Sócrates   71.0           True   <NA>      0.481840              0.8875\n",
      "2  Descartes   53.0          False   1.55     -0.905858              0.6625\n",
      "3  Nietzsche   55.0           True    1.7     -0.751670              0.6875\n"
     ]
    }
   ],
   "source": [
    "maximo_absoluto = max(abs(df['Idade']))\n",
    "\n",
    "df['Idade_norm_max_abs'] = df['Idade'] / maximo_absoluto\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vantagem da normalização pelo máximo absoluto é que ela mantém a esparsidade dos seus dados (isto é: não altera os valores que são zero). Aliado com a certeza que seus dados estão contidos em um intervalo entre $[-1,1]$ faz deste normalizador uma excelente escolha para treinar modelos como redes neurais artificiais, por exemplo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização pelo mínimo e máximo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <u>normalização pelo mínimo e máximo</u> modifica os dados de forma que, após a transformação, os dados tenham valor mínimo de 0 e valor máximo de 1. O valor transformado $m_i$ do exemplo $i$ depende do valor do atributo $x_i$ deste exemplo e do valor mínimo e valor máximo deste atributo considerando todo o dataset $x$:\n",
    "\n",
    "$$ m_i = \\frac{x_i - \\min(x_i)}{\\max(x) - \\min(x)} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Nome  Idade  Bigode épico? Altura  Idade_zscore  Idade_norm_max_abs   \n",
      "0     Platão   80.0           True   <NA>      1.175689              1.0000  \\\n",
      "1   Sócrates   71.0           True   <NA>      0.481840              0.8875   \n",
      "2  Descartes   53.0          False   1.55     -0.905858              0.6625   \n",
      "3  Nietzsche   55.0           True    1.7     -0.751670              0.6875   \n",
      "\n",
      "   Idade_norm_min_max  \n",
      "0            1.000000  \n",
      "1            0.666667  \n",
      "2            0.000000  \n",
      "3            0.074074  \n"
     ]
    }
   ],
   "source": [
    "maximo = df['Idade'].max()\n",
    "minimo = df['Idade'].min()\n",
    "\n",
    "df['Idade_norm_min_max'] = (df['Idade'] - minimo) / (maximo - minimo)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este normalizador tem a vantagem que você sabe exatamente o valor máximo e mínimo dos dados normalizados, facilitando a interpretação dos seus resultados. Note que você pode perder a esparsidade dos dados quando aplicar este normalizador em situações onde existem números positivos e negativos. Costuma não ser uma boa estratégia perder a esparsidade dos dados!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização utilizando o `scikit-learn`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A normalização de dados em experimentos de Aprendizado de Máquina realizados em Python é geralmente feita pelo excelente módulo `scikit-learn`. Existe uma seção inteira sobre isso no [Guia do Usuário](https://scikit-learn.org/stable/modules/preprocessing.html), vale muito a pena dar uma lida! Os normalizadores estão todos dentro do submódulo `preprocessing`. Veja na tabela abaixo.\n",
    "\n",
    "| Nome dentro do <code>scikit-learn</code>|Tipo de normalizador|\n",
    "|---|---|\n",
    "| <code>StandardScaler</code>|Normalizador padrão|\n",
    "| <code>MaxAbsScaler</code>|Normalizador pelo máximo absoluto|\n",
    "| <code>MinMaxScaler</code>|Normalizador pelo mínimo e máximo|\n",
    "\n",
    "Todos os normalizadores do `scikit-learn` funcionam da mesma maneira:\n",
    "\n",
    "1.  Garantir que os dados têm duas dimensões (requerimento do `scikit-learn`, não é uma limitação da técnica de normalização em si)\n",
    "2.  Criamos uma instância do normalizador\n",
    "3.  Ajustamos o normalizador aos dados\n",
    "4.  Usamos o método `transform` sempre que quisermos aplicar o normalizador\n",
    "5.  (Opcional) Usamos o método `inverse_transform` sempre que quisermos &ldquo;desnormalizar&rdquo;, ou seja, retornar dados normalizados para os valores não-normalizados.\n",
    "\n",
    "Vamos ver um exemplo com o `MinMaxScaler`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados originais\n",
      "[[80.]\n",
      " [71.]\n",
      " [53.]\n",
      " [55.]]\n",
      "\n",
      "Dados normalizados:\n",
      "[[1.        ]\n",
      " [0.66666667]\n",
      " [0.        ]\n",
      " [0.07407407]]\n",
      "\n",
      "Dados desnormalizados:\n",
      "[[80.]\n",
      " [71.]\n",
      " [53.]\n",
      " [55.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Passo 1: só é necessário se os dados tem apenas uma dimensão\n",
    "# Se seus dados já tem duas dimensões, não precisa fazer isso!\n",
    "x = df[\"Idade\"].values.reshape(-1, 1)\n",
    "\n",
    "# Passo 2: criar uma instância do normalizador\n",
    "normalizador = MinMaxScaler()\n",
    "\n",
    "# Passo 3: ajustar o normalizador aos dados\n",
    "normalizador.fit(x)\n",
    "\n",
    "# Passo 4: aplicar o normalizador usando o método `transform`\n",
    "idade_normalizada = normalizador.transform(x)\n",
    "\n",
    "# Passo 5: se desejamos recuperar os valores iniciais, usamos o `inverse_transform`\n",
    "idade_desnormalizada = normalizador.inverse_transform(idade_normalizada)\n",
    "\n",
    "# Ver resultados\n",
    "print(\"Dados originais\")\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "print(\"Dados normalizados:\")\n",
    "print(idade_normalizada)\n",
    "print()\n",
    "\n",
    "print(\"Dados desnormalizados:\")\n",
    "print(idade_desnormalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estratégia é similar para usar o `StandardScaler` e o `MaxAbsScaler` (ou qualquer outro normalizador do `scikit-learn`) e fica como exercício para o leitor atento. Os normalizadores do `scikit-learn` podem ser treinados em dados com múltiplas colunas ao mesmo tempo, teste para ver como é!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
