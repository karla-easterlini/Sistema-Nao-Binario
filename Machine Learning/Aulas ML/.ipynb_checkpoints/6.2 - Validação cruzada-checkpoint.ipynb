{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validação cruzada\n",
    "=================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No notebook 5.1 nós vimos que avaliar a performance de modelos utilizando os dados usados para treinar os modelos nos fornece uma métrica de performance que é *superestimada* (isto é, a performance do modelo aparenta ser melhor do que realmente é).\n",
    "\n",
    "A solução para buscar uma melhor forma de avaliar a performance dos modelos foi a separação dos dados em um conjunto de treino e um conjunto de teste.\n",
    "\n",
    "Aqui neste notebook veremos uma estratégia para *seleção de modelos*. Seleção de modelos é diferente de avaliação de modelos. Isto vai ficar claro ao longo deste notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os dados necessários\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de seguir em frente, precisamos de dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "DATASET_NAME = \"penguins\"\n",
    "FEATURES = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]\n",
    "TARGET = [\"body_mass_g\"]\n",
    "\n",
    "TAMANHO_TESTE = 0.1\n",
    "SEMENTE_ALEATORIA = 61455\n",
    "\n",
    "df = sns.load_dataset(DATASET_NAME)\n",
    "\n",
    "df = df.reindex(FEATURES + TARGET, axis=1)\n",
    "df = df.dropna()\n",
    "\n",
    "indices = df.index\n",
    "indices_treino, indices_teste = train_test_split(\n",
    "    indices, test_size=TAMANHO_TESTE, random_state=SEMENTE_ALEATORIA\n",
    ")\n",
    "\n",
    "df_treino = df.loc[indices_treino]\n",
    "df_teste = df.loc[indices_teste]\n",
    "\n",
    "X_treino = df_treino.reindex(FEATURES, axis=1).values\n",
    "y_treino = df_treino.reindex(TARGET, axis=1).values.ravel()\n",
    "\n",
    "X_teste = df_teste.reindex(FEATURES, axis=1).values\n",
    "y_teste = df_teste.reindex(TARGET, axis=1).values.ravel()\n",
    "\n",
    "X = df.reindex(FEATURES, axis=1).values\n",
    "y = df.reindex(TARGET, axis=1).values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O acaso vai me proteger&#x2026; se eu não forçar a barra\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No código abaixo, nós estamos treinando uma árvore de decisão nos dados dos pinguins que carregamos na seção anterior. Observe o que acontece com a performance do modelo quando variamos a semente aleatória (observe que a performance está sendo medida da maneira correta, isto é, no conjunto de teste).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Quantidade')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "N = 5000\n",
    "\n",
    "resultado = []\n",
    "\n",
    "for semente in range(N):\n",
    "    modelo_dt = DecisionTreeRegressor(random_state=semente)\n",
    "\n",
    "    modelo_dt.fit(X_treino, y_treino)\n",
    "\n",
    "    y_verdadeiro = y_teste\n",
    "    y_previsao = modelo_dt.predict(X_teste)\n",
    "    RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "    resultado.append(RMSE)\n",
    "\n",
    "figura, eixo = plt.subplots()\n",
    "eixo.hist(resultado)\n",
    "eixo.set_xlabel(\"RMSE\")\n",
    "eixo.set_ylabel(\"Quantidade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afinal de contas, qual é a performance deste modelo? Porque variando a semente aleatória a performance varia?\n",
    "\n",
    "Este experimento que realizamos acima nos mostra que mesmo pequenas variações nas árvores de decisão induzidas pelo modelo resultam em alterações na performance. Estas variações no modelo ocorrem pois alteramos a semente aleatória, releia o notebook 5.2 para relembrar que induzir uma árvore de decisão é um problema NP-difícil e que o `scikit-learn` usa um algoritmo que não necessariamente entrega a melhor resposta.\n",
    "\n",
    "Por puro acaso, variações no modelo podem prever melhor ou pior os dados de treino, e é por isso que vemos uma distribuição nos valores de performance neste experimento.\n",
    "\n",
    "Geralmente, não nos preocupamos com o acaso quando treinamos modelos pois esperamos que o efeito do acaso seja pequeno (isto é, assumimos que a nossa avaliação da performance no conjunto de teste é uma estimativa razoável). No entanto, quando &ldquo;forçamos a barra&rdquo; podemos observar situações inusitadas por puro efeito do acaso, como foi o caso do experimento que realizamos acima.\n",
    "\n",
    "Quando reusamos o mesmo conjunto de teste para diversos modelos diferentes, aumentamos a chance de observar modelos com estimativas de performance muito discrepantes (para mais ou para menos) por pura ação do acaso. Um artigo que discute de forma excelente isso é a referência [1].\n",
    "\n",
    "O nome técnico deste conceito é &ldquo;vazamento de dados&rdquo; ou *data leakage* em inglês (ver referência [2]). Quando usamos o mesmo conjunto de teste várias vezes, dizemos que a informação dos dados de teste &ldquo;vazaram&rdquo; para o treino (efeito do acaso discutido acima). Outra forma de ocorrer vazamento de dados é quando existem dados duplicados no seu conjunto de dados (isto é, dados com mesmos valores de atributos); desta forma você corre o risco de dados &ldquo;iguais&rdquo; a dados do conjunto de treino cairem no conjunto de teste durante seu split, o que faz com que seu modelo seja treinado com informações que deveriam ser novas (os dados de teste deveriam ser novidade para seu modelo).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação de modelos com validação cruzada $k$​-fold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma estratégia para reduzir o efeito do acaso para avaliar um modelo induzido por aprendizado de máquina é o processo de *validação cruzada* (cross-validation em inglês).\n",
    "\n",
    "A validação cruzada mais usada é a chamada de $k$​-fold, representada na imagem abaixo. Nesta estratégia, nós dividimos o conjunto de dados em $k$ subconjuntos diferentes de mesmo tamanho (ou o mais próximo possível disso). Em cada iteração da validação cruzada, um destes subconjuntos é designado como conjunto de teste e os demais como conjunto de treino de forma que todo subconjunto seja teste uma vez.\n",
    "\n",
    "Nesta estratégia, nós treinamos $k$ modelos e temos $k$ estimativas da performance. A média das $k$ estimativas de performance é o valor que usaremos para avaliar o modelo sendo estudado.\n",
    "\n",
    "![img](https://upload.wikimedia.org/wikipedia/commons/b/b5/K-fold_cross_validation_EN.svg)\n",
    "\n",
    "Observe que a estratégia de validação cruzada é menos susceptível ao acaso do que a estratégia de split em treino e teste que vimos anteriormente.\n",
    "\n",
    "A escolha do valor de $k$ é um ponto muito importante. Quanto maior o valor de $k$ maior o custo computacional do processo de validação cruzada. Quanto menor o valor de $k$ pior será sua estimativa da performance. Em geral, um valor de $k=10$ costuma ser muito bom, mas $k=5$ também é considerado bom e menos custoso.\n",
    "\n",
    "Vamos ver como fazer uma validação cruzada no `scikit-learn`. Note que aqui não fizemos o split de treino e teste pois quem está cuidando disso é a própria função `cross_val_score`. Outro detalhe é que a função `cross_val_score` pode receber o argumento `scoring` que é a medida da performance que temos interesse. Aqui queremos a métrica RMSE e por isso passamos o valor `neg_root_mean_squared_error`. Existem diversos scores possíveis que podemos utilizar para a validação cruzada. Você pode checar as que já estão embutidas no `scikit-learn` na [documentação](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As métricas foram:  [-532.24591524 -509.39389755 -488.16884736 -520.42827386 -411.81984925\n",
      " -553.26570577 -523.38687749 -460.25887856 -321.55984714 -540.27158203]\n",
      "\n",
      "A média das métricas é de:  -486.0799674242896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "NUM_FOLDS = 10\n",
    "\n",
    "modelo_dt = DecisionTreeRegressor()\n",
    "\n",
    "metricas = cross_val_score(\n",
    "    modelo_dt,\n",
    "    X,\n",
    "    y,\n",
    "    cv=NUM_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    ")\n",
    "\n",
    "print(\"As métricas foram: \", metricas)\n",
    "print()\n",
    "print(\"A média das métricas é de: \", metricas.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ué, como assim o RMSE deu negativo? Isso acontece porque o `scikit-learn` definiu que métricas com o nome de *score* devem todas seguir a mesma regra: quanto maior, melhor! No entanto, sabemos que quanto menor o RMSE melhor a performance do meu modelo. Para satisfazer a definição de score do `scikit-learn`, devemos usar o negativo do RMSE como score (por isso tem um `neg` na string que passamos no argumento `scoring`, vem de &ldquo;negativo&rdquo;). Basta você remover o sinal de negativo e terá seu RMSE tradicional como de costume.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A média das métricas é de:  486.0799674242896\n"
     ]
    }
   ],
   "source": [
    "print(\"A média das métricas é de: \", abs(metricas.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização de hiperparâmetros\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Avaliar* a performance de modelos é muito importante. No entanto, muitas vezes nós temos interesse em realizar o passo seguinte que é o de *selecionar* modelos. Pode parecer que são processos iguais mas não são!\n",
    "\n",
    "Seleção de modelos é escolher um bom conjunto de hiperparâmetros para um certo algoritmo de aprendizado de máquina. Este processo também é conhecido como *otimização de hiperparâmetros* ou *hyperparameter tuning* ou simplesmente *hp tuning*.\n",
    "\n",
    "Este processo envolve os conceitos de split treino-teste com a validação cruzada. Os passos são os seguintes:\n",
    "\n",
    "1.  Dividir o conjunto de dados em treino e teste;\n",
    "\n",
    "2.  Realizar validação cruzada considerando apenas o conjunto de treino. Registrar a performance de cada conjunto de hiperparâmetros testados. Escolher o conjunto de hiperparâmetros que resultou na melhor performance;\n",
    "\n",
    "3.  Treinar um modelo usando os hiperparâmetros encontrados no passo 2 em *todos* os dados de treino;\n",
    "\n",
    "4.  Avaliar a performance do modelo obtido no passo 3 no conjunto de teste obtido no passo 1.\n",
    "\n",
    "Uma representação visual pode ser conferida na imagem abaixo. A figura 16 da referência [1] mostra os passos discutidos acima.\n",
    "\n",
    "![img](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização de hiperparâmetros com `scikit-learn` (busca em grade)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Problemas de otimização* são problemas onde buscamos maximizar ou minimizar uma função objetivo. O problema de otimização de hiperparâmetros é um tipo de problema de otimização.\n",
    "\n",
    "Uma estratégia para resolver problemas de otimização é definir todos os valores possíveis dos parâmetros que estamos estudando (neste caso são os hiperparâmetros dos modelos) e estudar os resultados de todas as possíveis combinações entre eles. Esta é a estratégia chamada de *busca em grade*.\n",
    "\n",
    "Podemos realizar esta busca usando o `scikit-learn`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': None, 'max_features': None, 'min...</td>\n",
       "      <td>-467.491590</td>\n",
       "      <td>...</td>\n",
       "      <td>-565.560670</td>\n",
       "      <td>-417.847788</td>\n",
       "      <td>-526.265755</td>\n",
       "      <td>-394.493346</td>\n",
       "      <td>-449.513626</td>\n",
       "      <td>-606.526999</td>\n",
       "      <td>-618.112045</td>\n",
       "      <td>-504.100034</td>\n",
       "      <td>77.592883</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': None, 'max_features': None, 'min...</td>\n",
       "      <td>-472.190332</td>\n",
       "      <td>...</td>\n",
       "      <td>-491.848882</td>\n",
       "      <td>-407.168626</td>\n",
       "      <td>-530.862050</td>\n",
       "      <td>-406.747524</td>\n",
       "      <td>-453.045252</td>\n",
       "      <td>-610.054642</td>\n",
       "      <td>-615.731273</td>\n",
       "      <td>-489.498044</td>\n",
       "      <td>71.683847</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': None, 'max_features': None, 'min...</td>\n",
       "      <td>-495.056204</td>\n",
       "      <td>...</td>\n",
       "      <td>-466.439197</td>\n",
       "      <td>-384.365575</td>\n",
       "      <td>-512.696658</td>\n",
       "      <td>-416.700267</td>\n",
       "      <td>-479.376766</td>\n",
       "      <td>-593.949528</td>\n",
       "      <td>-606.058819</td>\n",
       "      <td>-486.133372</td>\n",
       "      <td>67.554362</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': None, 'max_features': None, 'min...</td>\n",
       "      <td>-471.438378</td>\n",
       "      <td>...</td>\n",
       "      <td>-553.458295</td>\n",
       "      <td>-377.877994</td>\n",
       "      <td>-496.460929</td>\n",
       "      <td>-388.421698</td>\n",
       "      <td>-470.481063</td>\n",
       "      <td>-566.906608</td>\n",
       "      <td>-558.863761</td>\n",
       "      <td>-476.306942</td>\n",
       "      <td>64.460420</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': None, 'max_features': None, 'min...</td>\n",
       "      <td>-408.172834</td>\n",
       "      <td>...</td>\n",
       "      <td>-538.163298</td>\n",
       "      <td>-380.371476</td>\n",
       "      <td>-467.351408</td>\n",
       "      <td>-408.980861</td>\n",
       "      <td>-477.405277</td>\n",
       "      <td>-569.220146</td>\n",
       "      <td>-460.953998</td>\n",
       "      <td>-459.204053</td>\n",
       "      <td>57.533787</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'log2', 'min...</td>\n",
       "      <td>-445.019208</td>\n",
       "      <td>...</td>\n",
       "      <td>-421.254795</td>\n",
       "      <td>-365.356101</td>\n",
       "      <td>-426.578104</td>\n",
       "      <td>-430.790955</td>\n",
       "      <td>-394.711076</td>\n",
       "      <td>-505.702711</td>\n",
       "      <td>-599.750831</td>\n",
       "      <td>-440.128763</td>\n",
       "      <td>63.660907</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'log2', 'min...</td>\n",
       "      <td>-392.154215</td>\n",
       "      <td>...</td>\n",
       "      <td>-439.913400</td>\n",
       "      <td>-330.846914</td>\n",
       "      <td>-495.654171</td>\n",
       "      <td>-332.109549</td>\n",
       "      <td>-311.677982</td>\n",
       "      <td>-549.833633</td>\n",
       "      <td>-479.618209</td>\n",
       "      <td>-406.199561</td>\n",
       "      <td>78.260133</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'log2', 'min...</td>\n",
       "      <td>-398.808638</td>\n",
       "      <td>...</td>\n",
       "      <td>-579.642759</td>\n",
       "      <td>-340.618646</td>\n",
       "      <td>-426.442765</td>\n",
       "      <td>-351.558544</td>\n",
       "      <td>-337.595935</td>\n",
       "      <td>-374.140045</td>\n",
       "      <td>-404.602792</td>\n",
       "      <td>-398.714455</td>\n",
       "      <td>67.057027</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'log2', 'min...</td>\n",
       "      <td>-480.877286</td>\n",
       "      <td>...</td>\n",
       "      <td>-514.482218</td>\n",
       "      <td>-358.766107</td>\n",
       "      <td>-586.083967</td>\n",
       "      <td>-340.278729</td>\n",
       "      <td>-330.897585</td>\n",
       "      <td>-334.652296</td>\n",
       "      <td>-451.677554</td>\n",
       "      <td>-407.466639</td>\n",
       "      <td>88.578940</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'log2', 'min...</td>\n",
       "      <td>-496.979769</td>\n",
       "      <td>...</td>\n",
       "      <td>-425.696130</td>\n",
       "      <td>-617.522272</td>\n",
       "      <td>-553.646460</td>\n",
       "      <td>-411.640875</td>\n",
       "      <td>-345.472000</td>\n",
       "      <td>-565.247713</td>\n",
       "      <td>-436.459036</td>\n",
       "      <td>-487.614852</td>\n",
       "      <td>78.913816</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time   \n",
       "0         0.000947      0.000100         0.000297        0.000032  \\\n",
       "1         0.000870      0.000104         0.000264        0.000029   \n",
       "2         0.000785      0.000068         0.000246        0.000013   \n",
       "3         0.000814      0.000100         0.000258        0.000034   \n",
       "4         0.000930      0.000213         0.000324        0.000101   \n",
       "..             ...           ...              ...             ...   \n",
       "379       0.000644      0.000041         0.000328        0.000033   \n",
       "380       0.000538      0.000061         0.000262        0.000036   \n",
       "381       0.000604      0.000118         0.000290        0.000068   \n",
       "382       0.000704      0.000071         0.000332        0.000015   \n",
       "383       0.000543      0.000095         0.000278        0.000049   \n",
       "\n",
       "    param_max_depth param_max_features param_min_samples_leaf   \n",
       "0              None               None                      1  \\\n",
       "1              None               None                      1   \n",
       "2              None               None                      1   \n",
       "3              None               None                      1   \n",
       "4              None               None                      2   \n",
       "..              ...                ...                    ...   \n",
       "379              10               log2                      3   \n",
       "380              10               log2                      4   \n",
       "381              10               log2                      4   \n",
       "382              10               log2                      4   \n",
       "383              10               log2                      4   \n",
       "\n",
       "    param_min_samples_split   \n",
       "0                         1  \\\n",
       "1                         2   \n",
       "2                         3   \n",
       "3                         4   \n",
       "4                         1   \n",
       "..                      ...   \n",
       "379                       4   \n",
       "380                       1   \n",
       "381                       2   \n",
       "382                       3   \n",
       "383                       4   \n",
       "\n",
       "                                                params  split0_test_score   \n",
       "0    {'max_depth': None, 'max_features': None, 'min...        -467.491590  \\\n",
       "1    {'max_depth': None, 'max_features': None, 'min...        -472.190332   \n",
       "2    {'max_depth': None, 'max_features': None, 'min...        -495.056204   \n",
       "3    {'max_depth': None, 'max_features': None, 'min...        -471.438378   \n",
       "4    {'max_depth': None, 'max_features': None, 'min...        -408.172834   \n",
       "..                                                 ...                ...   \n",
       "379  {'max_depth': 10, 'max_features': 'log2', 'min...        -445.019208   \n",
       "380  {'max_depth': 10, 'max_features': 'log2', 'min...        -392.154215   \n",
       "381  {'max_depth': 10, 'max_features': 'log2', 'min...        -398.808638   \n",
       "382  {'max_depth': 10, 'max_features': 'log2', 'min...        -480.877286   \n",
       "383  {'max_depth': 10, 'max_features': 'log2', 'min...        -496.979769   \n",
       "\n",
       "     ...  split3_test_score  split4_test_score  split5_test_score   \n",
       "0    ...        -565.560670        -417.847788        -526.265755  \\\n",
       "1    ...        -491.848882        -407.168626        -530.862050   \n",
       "2    ...        -466.439197        -384.365575        -512.696658   \n",
       "3    ...        -553.458295        -377.877994        -496.460929   \n",
       "4    ...        -538.163298        -380.371476        -467.351408   \n",
       "..   ...                ...                ...                ...   \n",
       "379  ...        -421.254795        -365.356101        -426.578104   \n",
       "380  ...        -439.913400        -330.846914        -495.654171   \n",
       "381  ...        -579.642759        -340.618646        -426.442765   \n",
       "382  ...        -514.482218        -358.766107        -586.083967   \n",
       "383  ...        -425.696130        -617.522272        -553.646460   \n",
       "\n",
       "     split6_test_score  split7_test_score  split8_test_score   \n",
       "0          -394.493346        -449.513626        -606.526999  \\\n",
       "1          -406.747524        -453.045252        -610.054642   \n",
       "2          -416.700267        -479.376766        -593.949528   \n",
       "3          -388.421698        -470.481063        -566.906608   \n",
       "4          -408.980861        -477.405277        -569.220146   \n",
       "..                 ...                ...                ...   \n",
       "379        -430.790955        -394.711076        -505.702711   \n",
       "380        -332.109549        -311.677982        -549.833633   \n",
       "381        -351.558544        -337.595935        -374.140045   \n",
       "382        -340.278729        -330.897585        -334.652296   \n",
       "383        -411.640875        -345.472000        -565.247713   \n",
       "\n",
       "     split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0          -618.112045      -504.100034       77.592883              351  \n",
       "1          -615.731273      -489.498044       71.683847              334  \n",
       "2          -606.058819      -486.133372       67.554362              329  \n",
       "3          -558.863761      -476.306942       64.460420              309  \n",
       "4          -460.953998      -459.204053       57.533787              267  \n",
       "..                 ...              ...             ...              ...  \n",
       "379        -599.750831      -440.128763       63.660907              206  \n",
       "380        -479.618209      -406.199561       78.260133               46  \n",
       "381        -404.602792      -398.714455       67.057027               28  \n",
       "382        -451.677554      -407.466639       88.578940               54  \n",
       "383        -436.459036      -487.614852       78.913816              330  \n",
       "\n",
       "[384 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "NUM_FOLDS = 10\n",
    "\n",
    "espaco_de_busca = {\n",
    "    \"max_depth\": [None, 2, 3, 5, 7, 10],\n",
    "    \"min_samples_split\": [1, 2, 3, 4],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4],\n",
    "    \"max_features\": [None, 0.33, \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "modelo_dt = DecisionTreeRegressor()\n",
    "\n",
    "buscador = GridSearchCV(\n",
    "    modelo_dt,\n",
    "    espaco_de_busca,\n",
    "    cv=NUM_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    refit=True,  # reajusta o melhor modelo com todos os dados de treino\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "buscador.fit(X_treino, y_treino)\n",
    "\n",
    "resultados = pd.DataFrame(buscador.cv_results_)\n",
    "# resultados = resultados.reindex(\n",
    "#     [\"mean_test_score\", \"std_test_score\", \"params\"], axis=1\n",
    "# )\n",
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver o resultado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A melhor métrica (considerando dados de treino) foi de  373.35721786504513\n",
      "O conjunto de hiperparâmetros que resultou nesta métrica foi  {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"A melhor métrica (considerando dados de treino) foi de \", abs(buscador.best_score_))\n",
    "print(\"O conjunto de hiperparâmetros que resultou nesta métrica foi \", buscador.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos estimar a performance deste modelo para dados que nunca viu!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O RMSE do modelo escolhido foi de 376.37149081195366 unidades de y.\n"
     ]
    }
   ],
   "source": [
    "y_verdadeiro = y_teste\n",
    "y_previsao = buscador.predict(X_teste)\n",
    "RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "print(f\"O RMSE do modelo escolhido foi de {RMSE} unidades de y.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização de hiperparâmetros com `scikit-learn` (busca aleatória)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A busca em grade que vimos na seção anterior irá testar todas as combinações possíveis dentro do espaço de busca. Isso pode ser muito custoso se o espaço de busca for muito grande! Para resolver este problema, podemos usar a *busca aleatória* que, como o próprio nome sugere, irá combinar os hiperparâmetros do espaço de busca de forma aleatória em busca de um bom conjunto de hiperparâmetros.\n",
    "\n",
    "Esta estratégia costuma ser menos custosa, mas em contrapartida não temos garantia de que o melhor conjunto de hiperparâmetros será sorteado durante a busca.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>{'min_samples_split': 4, 'min_samples_leaf': 3...</td>\n",
       "      <td>-418.918251</td>\n",
       "      <td>...</td>\n",
       "      <td>-375.698707</td>\n",
       "      <td>-361.393260</td>\n",
       "      <td>-417.382343</td>\n",
       "      <td>-402.744452</td>\n",
       "      <td>-389.403156</td>\n",
       "      <td>-536.763862</td>\n",
       "      <td>-417.632323</td>\n",
       "      <td>-410.201319</td>\n",
       "      <td>47.795200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>{'min_samples_split': 4, 'min_samples_leaf': 4...</td>\n",
       "      <td>-709.386402</td>\n",
       "      <td>...</td>\n",
       "      <td>-600.778806</td>\n",
       "      <td>-499.840421</td>\n",
       "      <td>-508.433558</td>\n",
       "      <td>-494.712662</td>\n",
       "      <td>-409.158198</td>\n",
       "      <td>-540.065408</td>\n",
       "      <td>-452.382719</td>\n",
       "      <td>-518.908547</td>\n",
       "      <td>91.128768</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 4...</td>\n",
       "      <td>-368.692260</td>\n",
       "      <td>...</td>\n",
       "      <td>-542.621013</td>\n",
       "      <td>-554.652189</td>\n",
       "      <td>-509.045013</td>\n",
       "      <td>-346.201061</td>\n",
       "      <td>-368.819704</td>\n",
       "      <td>-500.681425</td>\n",
       "      <td>-432.568538</td>\n",
       "      <td>-458.962953</td>\n",
       "      <td>98.836937</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>None</td>\n",
       "      <td>{'min_samples_split': 3, 'min_samples_leaf': 1...</td>\n",
       "      <td>-397.490870</td>\n",
       "      <td>...</td>\n",
       "      <td>-485.822175</td>\n",
       "      <td>-428.048837</td>\n",
       "      <td>-444.188504</td>\n",
       "      <td>-380.444350</td>\n",
       "      <td>-451.554030</td>\n",
       "      <td>-478.822340</td>\n",
       "      <td>-466.072911</td>\n",
       "      <td>-435.640702</td>\n",
       "      <td>36.831516</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>{'min_samples_split': 3, 'min_samples_leaf': 4...</td>\n",
       "      <td>-648.404553</td>\n",
       "      <td>...</td>\n",
       "      <td>-408.236187</td>\n",
       "      <td>-327.007515</td>\n",
       "      <td>-471.311480</td>\n",
       "      <td>-331.136826</td>\n",
       "      <td>-296.882596</td>\n",
       "      <td>-544.584055</td>\n",
       "      <td>-402.208573</td>\n",
       "      <td>-426.480607</td>\n",
       "      <td>107.609033</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'min_samples_split': 1, 'min_samples_leaf': 4...</td>\n",
       "      <td>-409.973433</td>\n",
       "      <td>...</td>\n",
       "      <td>-590.856513</td>\n",
       "      <td>-533.401523</td>\n",
       "      <td>-523.986748</td>\n",
       "      <td>-492.075565</td>\n",
       "      <td>-400.009591</td>\n",
       "      <td>-460.155092</td>\n",
       "      <td>-450.819074</td>\n",
       "      <td>-526.762184</td>\n",
       "      <td>104.644927</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2</td>\n",
       "      <td>{'min_samples_split': 1, 'min_samples_leaf': 1...</td>\n",
       "      <td>-423.754419</td>\n",
       "      <td>...</td>\n",
       "      <td>-591.447794</td>\n",
       "      <td>-483.691201</td>\n",
       "      <td>-556.923365</td>\n",
       "      <td>-513.006068</td>\n",
       "      <td>-378.553382</td>\n",
       "      <td>-692.029006</td>\n",
       "      <td>-601.387519</td>\n",
       "      <td>-499.077802</td>\n",
       "      <td>105.609467</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 2...</td>\n",
       "      <td>-439.658239</td>\n",
       "      <td>...</td>\n",
       "      <td>-418.500450</td>\n",
       "      <td>-353.327583</td>\n",
       "      <td>-438.244404</td>\n",
       "      <td>-396.670925</td>\n",
       "      <td>-355.064424</td>\n",
       "      <td>-479.887956</td>\n",
       "      <td>-412.760597</td>\n",
       "      <td>-398.492176</td>\n",
       "      <td>44.867232</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>7</td>\n",
       "      <td>{'min_samples_split': 4, 'min_samples_leaf': 4...</td>\n",
       "      <td>-453.143716</td>\n",
       "      <td>...</td>\n",
       "      <td>-447.521543</td>\n",
       "      <td>-289.632657</td>\n",
       "      <td>-444.491233</td>\n",
       "      <td>-563.260569</td>\n",
       "      <td>-267.713546</td>\n",
       "      <td>-443.936797</td>\n",
       "      <td>-480.091255</td>\n",
       "      <td>-418.215109</td>\n",
       "      <td>82.736575</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 2...</td>\n",
       "      <td>-741.317086</td>\n",
       "      <td>...</td>\n",
       "      <td>-600.778806</td>\n",
       "      <td>-465.005933</td>\n",
       "      <td>-585.641732</td>\n",
       "      <td>-507.147525</td>\n",
       "      <td>-464.245497</td>\n",
       "      <td>-480.233122</td>\n",
       "      <td>-443.300648</td>\n",
       "      <td>-564.443977</td>\n",
       "      <td>148.174801</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time   \n",
       "0        0.000911      0.000137         0.000345        0.000064  \\\n",
       "1        0.000560      0.000090         0.000297        0.000040   \n",
       "2        0.000556      0.000061         0.000262        0.000022   \n",
       "3        0.000624      0.000067         0.000257        0.000024   \n",
       "4        0.000548      0.000090         0.000289        0.000048   \n",
       "..            ...           ...              ...             ...   \n",
       "95       0.000522      0.000072         0.000290        0.000052   \n",
       "96       0.000590      0.000108         0.000315        0.000060   \n",
       "97       0.000642      0.000112         0.000302        0.000065   \n",
       "98       0.000602      0.000132         0.000294        0.000067   \n",
       "99       0.000449      0.000084         0.000252        0.000048   \n",
       "\n",
       "   param_min_samples_split param_min_samples_leaf param_max_features   \n",
       "0                        4                      3               None  \\\n",
       "1                        4                      4               sqrt   \n",
       "2                        2                      4               sqrt   \n",
       "3                        3                      1               0.33   \n",
       "4                        3                      4               sqrt   \n",
       "..                     ...                    ...                ...   \n",
       "95                       1                      4               log2   \n",
       "96                       1                      1               0.33   \n",
       "97                       2                      2               None   \n",
       "98                       4                      4               log2   \n",
       "99                       2                      2               0.33   \n",
       "\n",
       "   param_max_depth                                             params   \n",
       "0                7  {'min_samples_split': 4, 'min_samples_leaf': 3...  \\\n",
       "1                2  {'min_samples_split': 4, 'min_samples_leaf': 4...   \n",
       "2               10  {'min_samples_split': 2, 'min_samples_leaf': 4...   \n",
       "3             None  {'min_samples_split': 3, 'min_samples_leaf': 1...   \n",
       "4                5  {'min_samples_split': 3, 'min_samples_leaf': 4...   \n",
       "..             ...                                                ...   \n",
       "95               2  {'min_samples_split': 1, 'min_samples_leaf': 4...   \n",
       "96               2  {'min_samples_split': 1, 'min_samples_leaf': 1...   \n",
       "97               3  {'min_samples_split': 2, 'min_samples_leaf': 2...   \n",
       "98               7  {'min_samples_split': 4, 'min_samples_leaf': 4...   \n",
       "99               2  {'min_samples_split': 2, 'min_samples_leaf': 2...   \n",
       "\n",
       "    split0_test_score  ...  split3_test_score  split4_test_score   \n",
       "0         -418.918251  ...        -375.698707        -361.393260  \\\n",
       "1         -709.386402  ...        -600.778806        -499.840421   \n",
       "2         -368.692260  ...        -542.621013        -554.652189   \n",
       "3         -397.490870  ...        -485.822175        -428.048837   \n",
       "4         -648.404553  ...        -408.236187        -327.007515   \n",
       "..                ...  ...                ...                ...   \n",
       "95        -409.973433  ...        -590.856513        -533.401523   \n",
       "96        -423.754419  ...        -591.447794        -483.691201   \n",
       "97        -439.658239  ...        -418.500450        -353.327583   \n",
       "98        -453.143716  ...        -447.521543        -289.632657   \n",
       "99        -741.317086  ...        -600.778806        -465.005933   \n",
       "\n",
       "    split5_test_score  split6_test_score  split7_test_score   \n",
       "0         -417.382343        -402.744452        -389.403156  \\\n",
       "1         -508.433558        -494.712662        -409.158198   \n",
       "2         -509.045013        -346.201061        -368.819704   \n",
       "3         -444.188504        -380.444350        -451.554030   \n",
       "4         -471.311480        -331.136826        -296.882596   \n",
       "..                ...                ...                ...   \n",
       "95        -523.986748        -492.075565        -400.009591   \n",
       "96        -556.923365        -513.006068        -378.553382   \n",
       "97        -438.244404        -396.670925        -355.064424   \n",
       "98        -444.491233        -563.260569        -267.713546   \n",
       "99        -585.641732        -507.147525        -464.245497   \n",
       "\n",
       "    split8_test_score  split9_test_score  mean_test_score  std_test_score   \n",
       "0         -536.763862        -417.632323      -410.201319       47.795200  \\\n",
       "1         -540.065408        -452.382719      -518.908547       91.128768   \n",
       "2         -500.681425        -432.568538      -458.962953       98.836937   \n",
       "3         -478.822340        -466.072911      -435.640702       36.831516   \n",
       "4         -544.584055        -402.208573      -426.480607      107.609033   \n",
       "..                ...                ...              ...             ...   \n",
       "95        -460.155092        -450.819074      -526.762184      104.644927   \n",
       "96        -692.029006        -601.387519      -499.077802      105.609467   \n",
       "97        -479.887956        -412.760597      -398.492176       44.867232   \n",
       "98        -443.936797        -480.091255      -418.215109       82.736575   \n",
       "99        -480.233122        -443.300648      -564.443977      148.174801   \n",
       "\n",
       "    rank_test_score  \n",
       "0                10  \n",
       "1                90  \n",
       "2                67  \n",
       "3                38  \n",
       "4                29  \n",
       "..              ...  \n",
       "95               92  \n",
       "96               84  \n",
       "97                1  \n",
       "98               17  \n",
       "99               99  \n",
       "\n",
       "[100 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "NUM_FOLDS = 10\n",
    "NUM_ITERACOES = 100\n",
    "\n",
    "espaco_de_busca = {\n",
    "    \"max_depth\": [None, 2, 3, 5, 7, 10],\n",
    "    \"min_samples_split\": [1, 2, 3, 4],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4],\n",
    "    \"max_features\": [None, 0.33, \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "modelo_dt = DecisionTreeRegressor()\n",
    "\n",
    "buscador = RandomizedSearchCV(\n",
    "    modelo_dt,\n",
    "    espaco_de_busca,\n",
    "    n_iter=NUM_ITERACOES,\n",
    "    cv=NUM_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    refit=True,  # reajusta o melhor modelo com todos os dados de treino\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "buscador.fit(X_treino, y_treino)\n",
    "\n",
    "resultados = pd.DataFrame(buscador.cv_results_)\n",
    "# resultados = resultados.reindex(\n",
    "#     [\"mean_test_score\", \"std_test_score\", \"params\"], axis=1\n",
    "# )\n",
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver o resultado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A melhor métrica (considerando dados de treino) foi de  398.49217574308653\n",
      "O conjunto de hiperparâmetros que resultou nesta métrica foi  {'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "print(\"A melhor métrica (considerando dados de treino) foi de \", abs(buscador.best_score_))\n",
    "print(\"O conjunto de hiperparâmetros que resultou nesta métrica foi \", buscador.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos estimar a performance deste modelo para dados que nunca viu!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O RMSE do modelo escolhido foi de 398.25285598626624 unidades de y.\n"
     ]
    }
   ],
   "source": [
    "y_verdadeiro = y_teste\n",
    "y_previsao = buscador.predict(X_teste)\n",
    "RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "print(f\"O RMSE do modelo escolhido foi de {RMSE} unidades de y.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que fazer quando se tem um grande conjunto de dados?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando temos um *grande* conjunto de dados, a validação cruzada pode ser custosa demais de ser realizada. Neste caso, podemos realizar o *método da separação em 3 partes* (3-way holdout method em inglês), também conhecido como *split de treino-teste-validação*. Os passos são os seguintes:\n",
    "\n",
    "1.  Dividir o conjunto de dados em treino, teste e validação (uma divisão usual é 80-10-10);\n",
    "\n",
    "2.  Treinar modelos com diferentes hiperparâmetros apenas no conjunto de treino. Escolher o conjunto de hiperparâmetros que apresentar melhor performance na previsão do conjunto de validação.\n",
    "\n",
    "3.  Treinar um modelo usando os hiperparâmetros encontrados no passo 2 considerando todos os dados de treino e validação;\n",
    "\n",
    "4.  Avaliar a performance do modelo obtido no passo 3 no conjunto de teste obtido no passo 1.\n",
    "\n",
    "Para mais informações ver a seção 3.3 da referência [1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  RASCHKA, Sebastian. Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning. 2020. Disponível em: [http://arxiv.org/abs/1811.12808](http://arxiv.org/abs/1811.12808). Acesso em: 2 jul. 2023.\n",
    "\n",
    "2.  KAUFMAN, Shachar; ROSSET, Saharon; PERLICH, Claudia; et al. Leakage in data mining: Formulation, detection, and avoidance. ACM Transactions on Knowledge Discovery from Data, v. 6, n. 4, p. 15:1-15:21, 2012.\n",
    "\n",
    "3.  Guia sobre validação cruzada do `scikit-learn` [https://scikit-learn.org/stable/modules/cross_validation.html](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "4.  Tutorial sobre validação cruzada [https://dev.to/balapriya/cross-validation-and-hyperparameter-search-in-scikit-learn-a-complete-guide-5ed8](https://dev.to/balapriya/cross-validation-and-hyperparameter-search-in-scikit-learn-a-complete-guide-5ed8)\n",
    "\n",
    "5.  Documentação da validação cruzada com busca em grade [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    "6.  Documentação da validação cruzada com busca aleatória [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
